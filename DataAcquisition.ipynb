{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Objectives\n",
    "What is the relationship between the usage of social networks and mental health? (+/-) <br>\n",
    "What are the topics related to mental health and social networks?<br>\n",
    "Can we predict some mental health metric based on the usage of social networks?\n",
    "\n",
    "#### Similar works\n",
    "A work that is similar to mine is the [second place in the arquivo.pt award in 2022](ref:https://sobre.arquivo.pt/en/meet-the-winners-of-the-arquivo-pt-award-2022/).<br>\n",
    "The referred work also explores the mental health subject, and goes through a topic modelling proccess.\n",
    "\n",
    "#### Data aquisition\n",
    "Firstly request all the articles regarding mental health, then, filter them by social networks terms. <br>After that,place all the relevant data in a dataframe structure and persist it in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max items the api can retrieve.\n",
    "API_MAX_ITEMS = str(500)\n",
    "\n",
    "# Terms related with mental health.\n",
    "# ref: https://www.psicanaliseclinica.com/doencas-mentais/\n",
    "mental_health_terms = ['\"saude mental\"', 'saude mental', '\"saúde mental\"', 'saúde mental', 'depressão', 'ansiedade', 'burnout', 'anorexia', 'bulimia', 'esquizofrenia']\n",
    "# Terms related with social networks.\n",
    "social_net_terms = ['redes sociais', 'rede social', 'Facebook', 'Instagram', 'Twitter', 'LinkedIn', 'Tik-tok']\n",
    "\n",
    "# Years to be analyzed.\n",
    "years = range(2004, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(url):\n",
    "    response = requests.get(url)\n",
    "    content_type = response.headers.get(\"content-type\")\n",
    "    response_content = ''\n",
    "    \n",
    "    if response.status_code == 200:        \n",
    "        if 'application/json' in content_type:\n",
    "            response_content = response.json()\n",
    "        elif 'text/plain' or 'text/html' in content_type:\n",
    "            response_content = response.text\n",
    "\n",
    "    return response.status_code, response_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Observador news site articles\n",
    "def obs_extract_text_from_class(url):\n",
    "    classes = ['longform_content', 'content', 'article-body-content', 'article-body', 'amp-wp-article-content']\n",
    "    code, text = make_request(url)\n",
    "    if code != 200:\n",
    "        code, text = make_request(url)\n",
    "        \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    full_text = ''\n",
    "    flag = -1\n",
    "    # Find all elements with the specified class\n",
    "    for c in classes:\n",
    "        #print('Searching for class ', c)\n",
    "        if flag == 1:\n",
    "            #print('Exiting for loop.')\n",
    "            break\n",
    "        # Find the specific class\n",
    "        divs = soup.find_all('div', class_ = c)\n",
    "        #print(divs)\n",
    "        if divs:\n",
    "            flag = 1\n",
    "            #print('Found class: ', c)\n",
    "            for div in divs:\n",
    "                p_tags = div.find_all('p')\n",
    "                for p in p_tags:\n",
    "                    full_text += p.text        \n",
    "\n",
    "    # Strip trailing whitespace\n",
    "    full_text = full_text.strip()\n",
    "    # Remove \\r\\n and extra spaces\n",
    "    clean_text = \" \".join(full_text.split())\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Publico news site articles\n",
    "def extract_text_from_class(url, class_name):\n",
    "    code, text = make_request(url)\n",
    "    if code != 200:\n",
    "        code, text = make_request(url)\n",
    "        \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    full_text = ''\n",
    "\n",
    "    # Find all elements with the specified class\n",
    "    if class_name == 'p':\n",
    "        elements = soup.find_all('p')\n",
    "    else:\n",
    "        # Find the specific class\n",
    "        divs = soup.find_all('div', class_=class_name)\n",
    "        for div in divs:\n",
    "            p_tags = div.find_all('p')\n",
    "            for p in p_tags:\n",
    "                full_text += p.text        \n",
    "    \n",
    "    if class_name == 'p':\n",
    "        # Concatenate all text from the elements into a single string\n",
    "        full_text = \" \".join(element.get_text(strip=True) for element in elements)\n",
    "    \n",
    "    # Strip trailing whitespace\n",
    "    full_text = full_text.strip()\n",
    "    # Remove \\r\\n and extra spaces\n",
    "    clean_text = \" \".join(full_text.split())\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting articles from Observador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_substrs = ['/Facebook','Partilhe os factos Partilhar: Incorporar:', '©', '(.)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_start_end_date(quarter, year):\n",
    "    start = '0' + str(int(quarter)+1)\n",
    "    end = '0' + str(int(quarter)+3)\n",
    "    \n",
    "    if len(start) > 2 :\n",
    "        start = start[-2:]\n",
    "        end = end[-2:]\n",
    "    \n",
    "    start = str(year) + start + '01'\n",
    "    end = str(year) + end + '31'\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def find_substrings(text, substrings):\n",
    "    found_term = -1\n",
    "    for term in substrings: \n",
    "        # find returns -1 when it doesnt find the term. \n",
    "        term_index = text.find(term)\n",
    "        if term_index > 0: \n",
    "            #print(f'Row:{i} - found term: {term}')\n",
    "            found_term = term_index\n",
    "            break\n",
    "    return found_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonloureiro/anaconda3/envs/MCD/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n",
      "Total articles found: 2991\n"
     ]
    }
   ],
   "source": [
    "# Initialize the lists\n",
    "news_site = []\n",
    "tstamp = []\n",
    "title = []\n",
    "text = []\n",
    "quarters = ['00', '03', '06', '09']\n",
    "linkToNoFrame = []\n",
    "linkToArchive = []\n",
    "\n",
    "def process_url(site, term, start, end, retries=3, delay=15):\n",
    "    url = f'https://arquivo.pt/textsearch?q={term}&from={start}&to={end}&siteSearch={site}&dedupValue=1&maxItems={API_MAX_ITEMS}&fields=linkToArchive,linkToNoFrame,tstamp,title'\n",
    "    #print(f\"Processing URL: {url}\")  # Debugging statement\n",
    "    for attempt in range(retries):\n",
    "        time.sleep(1)  # Wait before making the request\n",
    "        response_code, response_json = make_request(url)\n",
    "        if response_code == 200:\n",
    "            #print(f\"Response received for URL: {url}\")  # Debugging statement\n",
    "            results = []\n",
    "            for item in response_json['response_items']:\n",
    "                if item['linkToNoFrame'].find('/programas/') > -1 or item['title'].find('Tudo sobre:') > -1:\n",
    "                    continue\n",
    "                full_text = obs_extract_text_from_class(item['linkToNoFrame'])\n",
    "                if full_text and find_substrings(full_text, mental_health_terms) != -1 and item['title'] not in title:\n",
    "                    results.append({\n",
    "                        'site': site.replace('www.', ''),\n",
    "                        'tstamp': item['tstamp'],\n",
    "                        'title': item['title'],\n",
    "                        'text': full_text,\n",
    "                        'linkToNoFrame': item['linkToNoFrame'],\n",
    "                        'linkToArchive': item['linkToArchive']\n",
    "                    })\n",
    "            return results\n",
    "        else:\n",
    "            print(f\"Failed to get response for URL: {url} with status code: {response_code}, attempt {attempt + 1}/{retries}\")  # Debugging statement\n",
    "            time.sleep(delay)  # Wait before retrying\n",
    "    return []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for site in ['www.observador.pt', 'observador.pt']:\n",
    "        for t in mental_health_terms:\n",
    "            term = t.replace(' ', '%20')\n",
    "            for y in range(2014, 2021):\n",
    "                for i in range(len(quarters)):\n",
    "                    start, end = process_start_end_date(quarters[i], y)\n",
    "                    futures.append(executor.submit(process_url, site, term, start, end))\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        results = future.result()  # Get the results from the future\n",
    "        # if results:\n",
    "        #     print(f\"Results received: {results}\")  # Debugging statement\n",
    "        for result in results:\n",
    "            news_site.append(result['site'])\n",
    "            tstamp.append(result['tstamp'])\n",
    "            title.append(result['title'])\n",
    "            text.append(result['text'])\n",
    "            linkToNoFrame.append(result['linkToNoFrame'])\n",
    "            linkToArchive.append(result['linkToArchive'])\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(f\"Total articles found: {len(title)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>2988</td>\n",
       "      <td>2760</td>\n",
       "      <td>2729</td>\n",
       "      <td>2988</td>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>observador.pt</td>\n",
       "      <td>20191101182217</td>\n",
       "      <td>Depressão. Perceberam que a tristeza que senti...</td>\n",
       "      <td>Dias antes das eleições presidenciais nos EUA ...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201911011822...</td>\n",
       "      <td>https://arquivo.pt/wayback/20191101182217/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2991</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_site          tstamp  \\\n",
       "count            2991            2991   \n",
       "unique              1            2988   \n",
       "top     observador.pt  20191101182217   \n",
       "freq             2991               2   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                2991   \n",
       "unique                                               2760   \n",
       "top     Depressão. Perceberam que a tristeza que senti...   \n",
       "freq                                                    5   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                2991   \n",
       "unique                                               2729   \n",
       "top     Dias antes das eleições presidenciais nos EUA ...   \n",
       "freq                                                    4   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                2991   \n",
       "unique                                               2988   \n",
       "top     https://arquivo.pt/noFrame/replay/201911011822...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                2991  \n",
       "unique                                               2988  \n",
       "top     https://arquivo.pt/wayback/20191101182217/http...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'news_site': news_site,\n",
    "    'tstamp': tstamp,\n",
    "    'title': title,\n",
    "    'text': text,\n",
    "    'linkToNoFrame': linkToNoFrame,\n",
    "    'linkToArchive': linkToArchive,\n",
    "}\n",
    "\n",
    "obs_df = pd.DataFrame.from_dict(data)\n",
    "obs_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_substrings(content, substrs):\n",
    "    for s in substrs:\n",
    "        content = content.replace(s, '.')\n",
    "    content = content.replace('..', '.').strip()\n",
    "    return content\n",
    "\n",
    "def remove_by_regex(content, regex, replaced_by):\n",
    "    matches = re.findall(regex, content)\n",
    "    for matched in matches:\n",
    "        content = content.replace(matched, replaced_by)\n",
    "    return content\n",
    "\n",
    "def fix_sentence_with_regex(content, regex, replaced_by):\n",
    "    matches = re.findall(regex, content)\n",
    "    for matched in matches:\n",
    "        content = content.replace(matched, replaced_by + matched[-1])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df_preprocessed = obs_df.copy()\n",
    "for i in range(obs_df.shape[0]):\n",
    "    text = obs_df.loc[i, 'text']\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = remove_substrings(text, obs_substrs)\n",
    "    text = remove_by_regex(text, r'[A-ZÀ-Ý]+(?:\\s[A-ZÀ-Ý]+)*/OBSERVADOR', '.')\n",
    "    text = remove_by_regex(text, r'[A-Za-zÀ-Ýà-ý]+(?:\\s[A-Za-zÀ-Ýà-ý]+)*/Observador', '.')\n",
    "    text = text.replace('facebook', 'Facebook').replace('instagram', 'Instagram').replace('twitter', 'Twitter').replace('linkedin', 'LinkedIn').replace('tik-tok', 'Tik-tok')\n",
    "    \n",
    "    for term in mental_health_terms + social_net_terms:\n",
    "        pattern = rf'{term}[a-zA-Z]'\n",
    "        text = fix_sentence_with_regex(text, pattern, f'{term}.')\n",
    "\n",
    "    found_term = find_substrings(text, social_net_terms)\n",
    "    # if no term was found the variable found_term < 0\n",
    "    if found_term < 0:\n",
    "        obs_df_preprocessed = obs_df_preprocessed.drop(i, axis=0)\n",
    "    else:\n",
    "        obs_df_preprocessed.loc[i, 'text'] = text\n",
    "\n",
    "obs_df_preprocessed = obs_df_preprocessed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>669</td>\n",
       "      <td>625</td>\n",
       "      <td>623</td>\n",
       "      <td>669</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>observador.pt</td>\n",
       "      <td>20200319034042</td>\n",
       "      <td>Da esperança à ansiedade. Como olham bascos, g...</td>\n",
       "      <td>O surto de Covid-19 decretou o fecho de escola...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/202003190340...</td>\n",
       "      <td>https://arquivo.pt/wayback/20200319034042/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>670</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_site          tstamp  \\\n",
       "count             670             670   \n",
       "unique              1             669   \n",
       "top     observador.pt  20200319034042   \n",
       "freq              670               2   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                 670   \n",
       "unique                                                625   \n",
       "top     Da esperança à ansiedade. Como olham bascos, g...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                 670   \n",
       "unique                                                623   \n",
       "top     O surto de Covid-19 decretou o fecho de escola...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                 670   \n",
       "unique                                                669   \n",
       "top     https://arquivo.pt/noFrame/replay/202003190340...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                 670  \n",
       "unique                                                669  \n",
       "top     https://arquivo.pt/wayback/20200319034042/http...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_df_preprocessed.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(obs_df_preprocessed.shape[0]):\n",
    "#     print(obs_df_preprocessed.loc[i, 'text'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting articles from Publico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonloureiro/anaconda3/envs/MCD/lib/python3.10/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20150401&to=20150631&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20150701&to=20150931&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20151001&to=20151231&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20160101&to=20160331&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20160401&to=20160631&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20160701&to=20160931&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20161001&to=20161231&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20170101&to=20170331&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20170701&to=20170931&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20170401&to=20170631&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20171001&to=20171231&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=burnout&from=20180101&to=20180331&siteSearch=www.publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20091001&to=20091231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20090701&to=20090931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20100101&to=20100331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20100401&to=20100631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20100701&to=20100931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20101001&to=20101231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20110101&to=20110331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20110401&to=20110631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20110701&to=20110931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20111001&to=20111231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20120101&to=20120331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20120401&to=20120631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20091001&to=20091231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20090701&to=20090931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20100101&to=20100331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20100401&to=20100631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20100701&to=20100931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20101001&to=20101231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20110101&to=20110331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20110401&to=20110631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20110701&to=20110931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20111001&to=20111231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20120101&to=20120331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=\"saude%20mental\"&from=20120401&to=20120631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20180101&to=20180331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20180401&to=20180631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20180701&to=20180931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20181001&to=20181231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20190101&to=20190331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20190401&to=20190631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20190701&to=20190931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20191001&to=20191231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20200101&to=20200331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20200401&to=20200631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20200701&to=20200931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 1/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20180101&to=20180331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20180401&to=20180631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20180701&to=20180931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20181001&to=20181231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20190101&to=20190331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20190401&to=20190631&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20190701&to=20190931&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20191001&to=20191231&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Failed to get response for URL: https://arquivo.pt/textsearch?q=bulimia&from=20200101&to=20200331&siteSearch=publico.pt&dedupValue=1&maxItems=500&fields=linkToArchive,linkToNoFrame,tstamp,title with status code: 429, attempt 2/3\n",
      "Processing complete.\n",
      "Total articles found: 277\n"
     ]
    }
   ],
   "source": [
    "# Cleaning lists\n",
    "news_site = []\n",
    "tstamp = []\n",
    "title = []\n",
    "text = []\n",
    "quarters = ['00', '03', '06', '09']\n",
    "linkToNoFrame = []\n",
    "linkToArchive = []\n",
    "\n",
    "def process_url(site, term, start, end, retries=3, delay=15):\n",
    "    url = f'https://arquivo.pt/textsearch?q={term}&from={start}&to={end}&siteSearch={site}&dedupValue=1&maxItems={API_MAX_ITEMS}&fields=linkToArchive,linkToNoFrame,tstamp,title'\n",
    "    #print(f\"Processing URL: {url}\")  # Debugging statement\n",
    "    for attempt in range(retries):\n",
    "        time.sleep(1)  # Wait before making the request\n",
    "        response_code, response_json = make_request(url)\n",
    "        if response_code == 200:\n",
    "            #print(f\"Response received for URL: {url}\")  # Debugging statement\n",
    "            results = []\n",
    "            if response_code == 200:\n",
    "                for item in response_json['response_items']:\n",
    "                    year = int(item['tstamp'][:4])\n",
    "                    if year < 2005:\n",
    "                        class_name = \"p\"\n",
    "                    elif year >= 2005 and year < 2009:\n",
    "                        class_name = \"texto\"\n",
    "                    elif year >= 2009 and year < 2013:\n",
    "                        class_name = \"noticia\"\n",
    "                    elif year >= 2013 and year < 2017:\n",
    "                        class_name = \"entry-body\"\n",
    "                    else:\n",
    "                        class_name = \"story__body\"\n",
    "                        \n",
    "                    full_text = extract_text_from_class(item['linkToNoFrame'], class_name)\n",
    "                    if full_text and find_substrings(full_text, mental_health_terms) != -1 and item['title'] not in title:\n",
    "                        results.append({\n",
    "                            'site': site.replace('www.', ''),\n",
    "                            'tstamp': item['tstamp'],\n",
    "                            'title': item['title'],\n",
    "                            'text': full_text,\n",
    "                            'linkToNoFrame': item['linkToNoFrame'],\n",
    "                            'linkToArchive': item['linkToArchive']\n",
    "                        })\n",
    "            return results\n",
    "        else:\n",
    "            print(f\"Failed to get response for URL: {url} with status code: {response_code}, attempt {attempt + 1}/{retries}\")  # Debugging statement\n",
    "            time.sleep(delay)  # Wait before retrying\n",
    "    return []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for site in ['www.publico.pt', 'publico.pt']:\n",
    "        for t in mental_health_terms:\n",
    "            term = t.replace(' ', '%20')\n",
    "            for y in years:\n",
    "                for i in range(len(quarters)):\n",
    "                    start, end = process_start_end_date(quarters[i], y)\n",
    "                    futures.append(executor.submit(process_url, site, term, start, end))\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        results = future.result()  # Get the results from the future\n",
    "        # if results:\n",
    "        #     print(f\"Results received: {results}\")  # Debugging statement\n",
    "        for result in results:\n",
    "            news_site.append(result['site'])\n",
    "            tstamp.append(result['tstamp'])\n",
    "            title.append(result['title'])\n",
    "            text.append(result['text'])\n",
    "            linkToNoFrame.append(result['linkToNoFrame'])\n",
    "            linkToArchive.append(result['linkToArchive'])\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(f\"Total articles found: {len(title)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>277</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>publico.pt</td>\n",
       "      <td>20110705105955</td>\n",
       "      <td>Sobreviver à ansiedade | REVISTA_2 | PÚBLICO</td>\n",
       "      <td>Sob o mote “A Depressão dói. Mas pode deixar d...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201107051059...</td>\n",
       "      <td>https://arquivo.pt/wayback/20110705105955/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         news_site          tstamp  \\\n",
       "count          277             277   \n",
       "unique           1             277   \n",
       "top     publico.pt  20110705105955   \n",
       "freq           277               1   \n",
       "\n",
       "                                               title  \\\n",
       "count                                            277   \n",
       "unique                                           263   \n",
       "top     Sobreviver à ansiedade | REVISTA_2 | PÚBLICO   \n",
       "freq                                               3   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                 277   \n",
       "unique                                                264   \n",
       "top     Sob o mote “A Depressão dói. Mas pode deixar d...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                 277   \n",
       "unique                                                277   \n",
       "top     https://arquivo.pt/noFrame/replay/201107051059...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                 277  \n",
       "unique                                                277  \n",
       "top     https://arquivo.pt/wayback/20110705105955/http...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the DataFrame\n",
    "data = {\n",
    "    'news_site': news_site,\n",
    "    'tstamp': tstamp,\n",
    "    'title': title,\n",
    "    'text': text,\n",
    "    'linkToNoFrame': linkToNoFrame,\n",
    "    'linkToArchive': linkToArchive,\n",
    "}\n",
    "\n",
    "publico_df = pd.DataFrame.from_dict(data)\n",
    "publico_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_after_substrings(content, substrs):\n",
    "    for s in substrs:\n",
    "        index = content.find(s)\n",
    "        if index != -1:\n",
    "            content = content[:index].strip() + '.'\n",
    "            content = content.replace('..', '.')\n",
    "    return content\n",
    "\n",
    "def remove_photo_quote(content):\n",
    "    regex = r'Foto[A-Z]{1}'\n",
    "    matches = re.findall(regex, content)\n",
    "    for matched in matches:\n",
    "        content = content.replace(matched, matched[-1])\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrs = ['/Facebook','PUBA carregar...', 'PUB', 'Subscrever×', 'voltar ao índice', 'O melhor do Público no emailSubscreva gratuitamente as newsletters e receba o melhor da actualidade e os trabalhos mais profundos do Público.', 'Continuar a ler', 'A carregar', 'i-albumgrafia', 'i-album', 'Fotografia', 'Partilhar citaçãoPartilhar no FacebookPartilhar no Twitter']\n",
    "after_substrs = ['Mais populares', 'Ler mais', '©', 'Notícia publicada', 'Notícia actualizada', 'Texto editado por']\n",
    "\n",
    "def preprocess_data(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = remove_after_substrings(text, after_substrs)\n",
    "    text = remove_substrings(text, substrs)\n",
    "    text = remove_photo_quote(text)\n",
    "    text = text.replace('facebook', 'Facebook').replace('instagram', 'Instagram').replace('twitter', 'Twitter').replace('linkedin', 'LinkedIn').replace('tik-tok', 'Tik-tok')\n",
    "    for term in mental_health_terms + social_net_terms:\n",
    "        pattern = rf'{term}[a-zA-Z]'\n",
    "        text = fix_sentence_with_regex(text, pattern, f'{term}.')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "publico_df_preprocessed = publico_df.copy()\n",
    "\n",
    "for i in range(publico_df.shape[0]):\n",
    "    text = preprocess_data(publico_df.loc[i, 'text'])\n",
    "    found_term = find_substrings(text, social_net_terms)\n",
    "    # if no term was found the variable found_term < 0\n",
    "    if found_term < 0:\n",
    "        publico_df_preprocessed = publico_df_preprocessed.drop(i, axis=0)\n",
    "    else:\n",
    "        publico_df_preprocessed.loc[i, 'text'] = text\n",
    "\n",
    "publico_df_preprocessed = publico_df_preprocessed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>publico.pt</td>\n",
       "      <td>20190410191430</td>\n",
       "      <td>Harry, Meghan e Oprah juntos para uma série so...</td>\n",
       "      <td>Harry e Meghan anunciaram nesta quarta-feira o...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201904101914...</td>\n",
       "      <td>https://arquivo.pt/wayback/20190410191430/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>publico.pt</td>\n",
       "      <td>20110629190213</td>\n",
       "      <td>Programa do XIX Governo Constitucional - Polít...</td>\n",
       "      <td>- Garantindo aos ex‐combatentes a manutenção d...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201106291902...</td>\n",
       "      <td>https://arquivo.pt/wayback/20110629190213/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>publico.pt</td>\n",
       "      <td>20180803172219</td>\n",
       "      <td>Óbito | Morreu Rick Genest, o modelo conhecido...</td>\n",
       "      <td>Aos 32 anos, Rick Genest (1985-2018) foi encon...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201808031722...</td>\n",
       "      <td>https://arquivo.pt/wayback/20180803172219/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>publico.pt</td>\n",
       "      <td>20181113184825</td>\n",
       "      <td>Incêndios | Miley Cyrus, Neil Young entre os q...</td>\n",
       "      <td>Os cantores Miley Cyrus e Neil Young estão ent...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201811131848...</td>\n",
       "      <td>https://arquivo.pt/wayback/20181113184825/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publico.pt</td>\n",
       "      <td>20181203192427</td>\n",
       "      <td>Empreendedorismo | (Mulheres + “Startups”) x S...</td>\n",
       "      <td>Se abrir uma empresa de tecnologia é uma taref...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201812031924...</td>\n",
       "      <td>https://arquivo.pt/wayback/20181203192427/http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    news_site          tstamp  \\\n",
       "0  publico.pt  20190410191430   \n",
       "1  publico.pt  20110629190213   \n",
       "2  publico.pt  20180803172219   \n",
       "3  publico.pt  20181113184825   \n",
       "4  publico.pt  20181203192427   \n",
       "\n",
       "                                               title  \\\n",
       "0  Harry, Meghan e Oprah juntos para uma série so...   \n",
       "1  Programa do XIX Governo Constitucional - Polít...   \n",
       "2  Óbito | Morreu Rick Genest, o modelo conhecido...   \n",
       "3  Incêndios | Miley Cyrus, Neil Young entre os q...   \n",
       "4  Empreendedorismo | (Mulheres + “Startups”) x S...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Harry e Meghan anunciaram nesta quarta-feira o...   \n",
       "1  - Garantindo aos ex‐combatentes a manutenção d...   \n",
       "2  Aos 32 anos, Rick Genest (1985-2018) foi encon...   \n",
       "3  Os cantores Miley Cyrus e Neil Young estão ent...   \n",
       "4  Se abrir uma empresa de tecnologia é uma taref...   \n",
       "\n",
       "                                       linkToNoFrame  \\\n",
       "0  https://arquivo.pt/noFrame/replay/201904101914...   \n",
       "1  https://arquivo.pt/noFrame/replay/201106291902...   \n",
       "2  https://arquivo.pt/noFrame/replay/201808031722...   \n",
       "3  https://arquivo.pt/noFrame/replay/201811131848...   \n",
       "4  https://arquivo.pt/noFrame/replay/201812031924...   \n",
       "\n",
       "                                       linkToArchive  \n",
       "0  https://arquivo.pt/wayback/20190410191430/http...  \n",
       "1  https://arquivo.pt/wayback/20110629190213/http...  \n",
       "2  https://arquivo.pt/wayback/20180803172219/http...  \n",
       "3  https://arquivo.pt/wayback/20181113184825/http...  \n",
       "4  https://arquivo.pt/wayback/20181203192427/http...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(publico_df_preprocessed.shape)\n",
    "publico_df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(publico_df_preprocessed.shape[0]):\n",
    "#     print(publico_df_preprocessed.loc[i, 'text'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "      <td>3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3265</td>\n",
       "      <td>3022</td>\n",
       "      <td>2993</td>\n",
       "      <td>3265</td>\n",
       "      <td>3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>observador.pt</td>\n",
       "      <td>20200319034042</td>\n",
       "      <td>Depressão. Perceberam que a tristeza que senti...</td>\n",
       "      <td>Dias antes das eleições presidenciais nos EUA ...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/202003190340...</td>\n",
       "      <td>https://arquivo.pt/wayback/20200319034042/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2991</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_site          tstamp  \\\n",
       "count            3268            3268   \n",
       "unique              2            3265   \n",
       "top     observador.pt  20200319034042   \n",
       "freq             2991               2   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                3268   \n",
       "unique                                               3022   \n",
       "top     Depressão. Perceberam que a tristeza que senti...   \n",
       "freq                                                    5   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                3268   \n",
       "unique                                               2993   \n",
       "top     Dias antes das eleições presidenciais nos EUA ...   \n",
       "freq                                                    4   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                3268   \n",
       "unique                                               3265   \n",
       "top     https://arquivo.pt/noFrame/replay/202003190340...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                3268  \n",
       "unique                                               3265  \n",
       "top     https://arquivo.pt/wayback/20200319034042/http...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([publico_df, obs_df], axis=0, ignore_index=True) \n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>observador.pt</td>\n",
       "      <td>20110705105955</td>\n",
       "      <td>Rede de cuidados continuados de saúde mental a...</td>\n",
       "      <td>As unidades e equipas de cuidados continuados ...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201107051059...</td>\n",
       "      <td>https://arquivo.pt/wayback/20110705105955/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2435</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_site          tstamp  \\\n",
       "count            2681            2681   \n",
       "unique              2            2681   \n",
       "top     observador.pt  20110705105955   \n",
       "freq             2435               1   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                2681   \n",
       "unique                                               2681   \n",
       "top     Rede de cuidados continuados de saúde mental a...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                2681   \n",
       "unique                                               2681   \n",
       "top     As unidades e equipas de cuidados continuados ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                2681   \n",
       "unique                                               2681   \n",
       "top     https://arquivo.pt/noFrame/replay/201107051059...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                2681  \n",
       "unique                                               2681  \n",
       "top     https://arquivo.pt/wayback/20110705105955/http...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['text'],keep=False)\n",
    "df = df.drop_duplicates(subset=['title'],keep=False).reset_index(drop=True)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>704</td>\n",
       "      <td>657</td>\n",
       "      <td>656</td>\n",
       "      <td>704</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>observador.pt</td>\n",
       "      <td>20200319034042</td>\n",
       "      <td>Da esperança à ansiedade. Como olham bascos, g...</td>\n",
       "      <td>O surto de Covid-19 decretou o fecho de escola...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/202003190340...</td>\n",
       "      <td>https://arquivo.pt/wayback/20200319034042/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>670</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_site          tstamp  \\\n",
       "count             705             705   \n",
       "unique              2             704   \n",
       "top     observador.pt  20200319034042   \n",
       "freq              670               2   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                 705   \n",
       "unique                                                657   \n",
       "top     Da esperança à ansiedade. Como olham bascos, g...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                 705   \n",
       "unique                                                656   \n",
       "top     O surto de Covid-19 decretou o fecho de escola...   \n",
       "freq                                                    3   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                 705   \n",
       "unique                                                704   \n",
       "top     https://arquivo.pt/noFrame/replay/202003190340...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                 705  \n",
       "unique                                                704  \n",
       "top     https://arquivo.pt/wayback/20200319034042/http...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = pd.concat([publico_df_preprocessed, obs_df_preprocessed], axis=0, ignore_index=True) \n",
    "df_preprocessed.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>linkToNoFrame</th>\n",
       "      <th>linkToArchive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>observador.pt</td>\n",
       "      <td>20190410191430</td>\n",
       "      <td>Harry, Meghan e Oprah juntos para uma série so...</td>\n",
       "      <td>Harry e Meghan anunciaram nesta quarta-feira o...</td>\n",
       "      <td>https://arquivo.pt/noFrame/replay/201904101914...</td>\n",
       "      <td>https://arquivo.pt/wayback/20190410191430/http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>562</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            news_site          tstamp  \\\n",
       "count             589             589   \n",
       "unique              2             589   \n",
       "top     observador.pt  20190410191430   \n",
       "freq              562               1   \n",
       "\n",
       "                                                    title  \\\n",
       "count                                                 589   \n",
       "unique                                                589   \n",
       "top     Harry, Meghan e Oprah juntos para uma série so...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                     text  \\\n",
       "count                                                 589   \n",
       "unique                                                589   \n",
       "top     Harry e Meghan anunciaram nesta quarta-feira o...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                            linkToNoFrame  \\\n",
       "count                                                 589   \n",
       "unique                                                589   \n",
       "top     https://arquivo.pt/noFrame/replay/201904101914...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                            linkToArchive  \n",
       "count                                                 589  \n",
       "unique                                                589  \n",
       "top     https://arquivo.pt/wayback/20190410191430/http...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = df_preprocessed.drop_duplicates(subset=['text'],keep=False)\n",
    "df_preprocessed = df_preprocessed.drop_duplicates(subset=['title'],keep=False).reset_index(drop=True)\n",
    "df_preprocessed.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist into a csv file - a column for journal name, publication date, news title, article text, linkToNoFrame, linkToArchive\n",
    "df.to_csv('raw_data.csv')\n",
    "df_preprocessed.to_csv('preprocessed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
